{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration tests of federated data in time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append(\".../S-ADL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexanomalies.datasets.preprocessing_utils import scaling\n",
    "from SADL.federated_data.algorithms import flexanomalies\n",
    "from SADL.time_series.time_series_utils import TimeSeriesProcessor\n",
    "from SADL.time_series.time_series_datasets_uci import global_load as load_time_series \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of time series data set for testing and preprocessiong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_time_series('ai4i_2020_predictive_maintenance_dataset')   #name dataset in static datasets uci repo\n",
    "labels = y[\"Machine failure\"]\n",
    "X = X.drop('Type',axis=1)  # remove Type or apply one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from SADL.static_data.preprocessing.preprocessing_static import OneHotEncoderPreprocessing\n",
    "# encoder = OneHotEncoderPreprocessing(columns=['Type'])\n",
    "# data_encoded = encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SADL.time_series.preprocessing.preprocessing_ts import StandardScalerPreprocessing \n",
    "scaler = StandardScalerPreprocessing()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autoencoder Model for anomaly detection in time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"algorithm_\": \"autoencoder\",\n",
    "    \"contamination\":0.1,\n",
    "    \"label_parser\": None,\n",
    "    \"epochs\": 3,\n",
    "    \"input_dim\": X.shape[1],\n",
    "    \"batch_size\": 16,\n",
    "    \"neurons\": [16, 8, 16],\n",
    "    \"hidden_act\": [\"relu\", \"relu\", \"relu\"],\n",
    "    \"preprocess\":False,\n",
    "    \"w_size\": 10,\n",
    "    \"n_pred\": 1,\n",
    "     \"n_clients\":3,\n",
    "     \"n_rounds\":5,\n",
    "     }\n",
    "\n",
    "\n",
    "\n",
    "modelAE = flexanomalies.FlexAnomalyDetection(**kwargs)\n",
    "print(modelAE.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TimeSeriesProcessor(window_size= kwargs[\"w_size\"], step_size=1, future_prediction=False)\n",
    "X_train_windows, y_train_windows, X_test_windows, y_test_windows = processor.process_train_test(X_train, y_train, X_test, y_test)\n",
    "print(\"X_train shape:\", X_train_windows.shape)\n",
    "print(\"y_train shape:\", y_train_windows.shape)\n",
    "print(\"X_test shape:\", X_test_windows.shape)\n",
    "print(\"y_test shape:\", y_test_windows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAE.fit(X_train_windows,y_train_windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_pred = modelAE.decision_function(X_train_windows)\n",
    "print(\"Scores\",scores_pred)\n",
    "modelAE.predict(X_train_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAE.model.d_scores_ ==scores_pred\n",
    "modelAE.model.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAE.evaluate(X_test_windows, X_test_windows, label_test = y_test_windows.flatten().astype(\"int\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN_LSTM model for anomaly forcasting  in time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"algorithm_\": \"deepCNN_LSTM\",\n",
    "    \"contamination\":0.1,\n",
    "    \"label_parser\": None,\n",
    "    \"epochs\": 5,\n",
    "    \"input_dim\": X.shape[1],\n",
    "    \"batch_size\": 8,\n",
    "    \"filters_cnn\": [8, 6],\n",
    "    \"units_lstm\": [8,6],\n",
    "    \"kernel_size\": [4,4],\n",
    "    \"hidden_act\": [\"relu\", \"relu\"],\n",
    "    \"w_size\": 20,\n",
    "    \"n_pred\": 1,\n",
    "     \"n_clients\":2,\n",
    "     \"n_rounds\":3,\n",
    "     }\n",
    "\n",
    "\n",
    "\n",
    "modelDeep = flexanomalies.FlexAnomalyDetection(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor =   TimeSeriesProcessor(window_size= kwargs[\"w_size\"], step_size=1, future_prediction=True, n_pred=kwargs[\"n_pred\"])\n",
    "X_train_windows, y_train_windows, X_test_windows, y_test_windows, l_test_windows = processor.process_train_test(X_train, y_train, X_test, y_test,l_test=y_test)\n",
    "print(\"X_train shape:\", X_train_windows.shape)\n",
    "print(\"y_train shape:\", y_train_windows.shape)\n",
    "print(\"X_test shape:\", X_test_windows.shape)\n",
    "print(\"y_test shape:\", y_test_windows.shape)\n",
    "print(\"l_test shape:\",l_test_windows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDeep.fit(X_train_windows,y_train_windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDeep.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDeep.evaluate(X_test_windows, y_test_windows, label_test = l_test_windows.flatten().astype(\"int\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
