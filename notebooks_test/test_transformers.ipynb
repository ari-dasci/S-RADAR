{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/data/Beatriz/Doctorado GR/ADL_platform//S-ADL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: {'uci_id': 601, 'name': 'AI4I 2020 Predictive Maintenance Dataset', 'repository_url': 'https://archive.ics.uci.edu/dataset/601/ai4i+2020+predictive+maintenance+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/601/data.csv', 'abstract': 'The AI4I 2020 Predictive Maintenance Dataset is a synthetic dataset that reflects real predictive maintenance data encountered in industry.', 'area': 'Computer Science', 'tasks': ['Classification', 'Regression', 'Causal-Discovery'], 'characteristics': ['Multivariate', 'Time-Series'], 'num_instances': 10000, 'num_features': 6, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF'], 'index_col': ['UID', 'Product ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2020, 'last_updated': 'Wed Feb 14 2024', 'dataset_doi': '10.24432/C5HS5C', 'creators': [], 'intro_paper': {'ID': 386, 'type': 'NATIVE', 'title': 'Explainable Artificial Intelligence for Predictive Maintenance Applications', 'authors': 'S. Matzka', 'venue': 'International Conference on Artificial Intelligence for Industries', 'year': 2020, 'journal': None, 'DOI': '10.1109/AI4I49448.2020.00023', 'URL': 'https://www.semanticscholar.org/paper/b609c8e9ec6a2b8c642810953ef6dffe5766f7c1', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Since real predictive maintenance datasets are generally difficult to obtain and in particular difficult to publish, we present and provide a synthetic dataset that reflects real predictive maintenance encountered in industry to the best of our knowledge.\\r\\n\\r\\n\\r\\n\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': \"The dataset consists of 10 000 data points stored as rows with 14 features in columns\\r\\nUID: unique identifier ranging from 1 to 10000\\r\\nproduct ID: consisting of a letter L, M, or H for low (50% of all products), medium (30%) and high (20%) as product quality variants and a variant-specific serial number\\r\\nair temperature [K]: generated using a random walk process later normalized to a standard deviation of 2 K around 300 K\\r\\nprocess temperature [K]: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.\\r\\nrotational speed [rpm]: calculated from a power of 2860 W, overlaid with a normally distributed noise\\r\\ntorque [Nm]: torque values are normally distributed around 40 Nm with a Ïƒ = 10 Nm and no negative values. \\r\\ntool wear [min]: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process. and a\\r\\n'machine failure' label that indicates, whether the machine has failed in this particular datapoint for any of the following failure modes are true.\\r\\n\\r\\nThe machine failure consists of five independent failure modes\\r\\ntool wear failure (TWF): the tool will be replaced of fail at a randomly selected tool wear time between 200 â€“ 240 mins (120 times in our dataset). At this point in time, the tool is replaced 69 times, and fails 51 times (randomly assigned).\\r\\nheat dissipation failure (HDF): heat dissipation causes a process failure, if the difference between air- and process temperature is below 8.6 K and the toolâ€™s rotational speed is below 1380 rpm. This is the case for 115 data points.\\r\\npower failure (PWF): the product of torque and rotational speed (in rad/s) equals the power required for the process. If this power is below 3500 W or above 9000 W, the process fails, which is the case 95 times in our dataset.\\r\\noverstrain failure (OSF): if the product of tool wear and torque exceeds 11,000 minNm for the L product variant (12,000 M, 13,000 H), the process fails due to overstrain. This is true for 98 datapoints.\\r\\nrandom failures (RNF): each process has a chance of 0,1 % to fail regardless of its process parameters. This is the case for only 5 datapoints, less than could be expected for 10,000 datapoints in our dataset.\\r\\n\\r\\nIf at least one of the above failure modes is true, the process fails and the 'machine failure' label is set to 1. It is therefore not transparent to the machine learning method, which of the failure modes has caused the process to fail \", 'citation': None}}\n",
      "Variable information:                    name     role         type demographic description units  \\\n",
      "0                   UID       ID      Integer        None        None  None   \n",
      "1            Product ID       ID  Categorical        None        None  None   \n",
      "2                  Type  Feature  Categorical        None        None  None   \n",
      "3       Air temperature  Feature   Continuous        None        None     K   \n",
      "4   Process temperature  Feature   Continuous        None        None     K   \n",
      "5      Rotational speed  Feature      Integer        None        None   rpm   \n",
      "6                Torque  Feature   Continuous        None        None    Nm   \n",
      "7             Tool wear  Feature      Integer        None        None   min   \n",
      "8       Machine failure   Target      Integer        None        None  None   \n",
      "9                   TWF   Target      Integer        None        None  None   \n",
      "10                  HDF   Target      Integer        None        None  None   \n",
      "11                  PWF   Target      Integer        None        None  None   \n",
      "12                  OSF   Target      Integer        None        None  None   \n",
      "13                  RNF   Target      Integer        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n"
     ]
    }
   ],
   "source": [
    "from SADL.time_series.time_series_datasets_uci import global_load as load_time_series \n",
    "from sklearn.model_selection import train_test_split\n",
    "X,y = load_time_series('ai4i_2020_predictive_maintenance_dataset')   #name dataset in static datasets uci repo\n",
    "labels = y[\"Machine failure\"]\n",
    "X = X.drop('Type',axis=1)  # remove Type or apply one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 5) (2000, 5) (8000,) (2000,)\n"
     ]
    }
   ],
   "source": [
    "from SADL.time_series.preprocessing.preprocessing_ts import StandardScalerPreprocessing \n",
    "scaler = StandardScalerPreprocessing()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Params: {'label_parser': <function <lambda> at 0x7a68bb329e10>, 'train_epochs': 10, 'batch_size': 16, 'lr': 0.001} \n",
      "Model Params: {'algorithm_': 'Transformer', 'size_enc_in': 5, 'size_dec_in': 5, 'ulayers_feedfwd': 128, 'seq_len': 24, 'd_qk': 64, 'd_v': 64, 'd_model': 64, 'n_layers': 2, 'n_heads': 8, 'dropout_rate': 0.1, 'attns_outs': False}\n"
     ]
    }
   ],
   "source": [
    "from SADL.time_series.algorithms import transformers\n",
    "from SADL.time_series.time_series_utils import TimeSeriesProcessor\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "batch_size = 16\n",
    "seq_len = 24\n",
    "input_dim = 5  # tanto encoder como decoder\n",
    "d_model = 64\n",
    "\n",
    "# Simulamos series de entrada\n",
    "X = torch.randn(batch_size, seq_len, input_dim)\n",
    "\n",
    "# Instanciamos el modelo Transformer\n",
    "kwargs ={\n",
    "    \"algorithm_\": \"Transformer\",\n",
    "    \"label_parser\": lambda scores: (scores > np.percentile(scores, 95)).astype(int),\n",
    "    \"size_enc_in\":input_dim,\n",
    "    \"size_dec_in\": input_dim,\n",
    "    \"ulayers_feedfwd\": 128,\n",
    "    \"seq_len\":seq_len,\n",
    "    \"d_qk\":64,\n",
    "    \"d_v\":64,\n",
    "    \"d_model\":d_model,\n",
    "    \"n_layers\": 2,\n",
    "    \"n_heads\": 8,\n",
    "   \"dropout_rate\": 0.1,\n",
    "   \"attns_outs\":False, \n",
    "    \"train_epochs\": 10,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"lr\": 1e-3\n",
    "    }\n",
    "    \n",
    "\n",
    "model = transformers.TransformersAnomalyDetection(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 5) (2000, 5) (8000,) (2000,)\n"
     ]
    }
   ],
   "source": [
    "processor = TimeSeriesProcessor(window_size= seq_len, step_size=1, future_prediction=False)\n",
    "X_train_windows, y_train_windows, X_test_windows, y_test_windows = processor.process_train_test(X_train, y_train, X_test, y_test)\n",
    "print(\"X_train shape:\", X_train_windows.shape)\n",
    "print(\"y_train shape:\", y_train_windows.shape)\n",
    "print(\"X_test shape:\", X_test_windows.shape)\n",
    "print(\"y_test shape:\", y_test_windows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly scores: torch.Size([16])\n",
      "Predicted labels: torch.Size([384, 5])\n"
     ]
    }
   ],
   "source": [
    "scores = model.decision_function(X)\n",
    "labels = model.predict(X)\n",
    "\n",
    "print(\"Anomaly scores:\", scores.shape)\n",
    "print(\"Predicted labels:\", labels.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
