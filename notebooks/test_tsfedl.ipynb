{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document a brief usage manual for the TSFEDL library under the S-ADL library.\n",
    "\n",
    "First we are going to load some data from the KDDCup99 dataset, which is currently used for testing and is also inside the library as an utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset KDD99Cup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the dataset utility for time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SADL.time_series.time_series_datasets as dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset loading process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn \n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "if not os.path.exists(os.path.join(os.getcwd(),'test.pkl')):\n",
    "    data, attack_types, classes = dataset.readKDDCup99Dataset()\n",
    "    data = sklearn.preprocessing.StandardScaler().fit_transform(data)\n",
    "\n",
    "    attack_types_dict = {}\n",
    "    cont=0\n",
    "    for att in attack_types:\n",
    "        attack_types_dict[att]=cont\n",
    "        cont+=1\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        classes[i] = attack_types_dict[classes[i]]\n",
    "\n",
    "    classes[classes!=attack_types_dict[\"normal\"]] = 1\n",
    "    classes[classes==attack_types_dict[\"normal\"]] = 0\n",
    "    classes_test = classes[-500000:]\n",
    "\n",
    "    normal_train = np.where(classes[:-500000]==0)[0][:10000]\n",
    "    train_data = data[normal_train]\n",
    "\n",
    "    with open('test.pkl','wb') as f:\n",
    "        pkl.dump(train_data, f)\n",
    "else: \n",
    "    with open('test.pkl','rb') as f:\n",
    "        train_data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-ADL/TSFEDL implemented models\n",
    "\n",
    "S-ADL has coverage for 23 models implemented in TSFEDL Library. You can instantiate these models by adding the parameter model=\"\" to the kwargs object. The dictionary of the available models is: \n",
    "\n",
    "    \"ohshulih\" : OhShuLih,\n",
    "    \"yibogao\": YiboGao,\n",
    "    \"liohshu\": LihOhShu,\n",
    "    \"yaoqihang\" : YaoQihang,\n",
    "    \"htetmyetlynn\" : HtetMyetLynn,\n",
    "    \"yildirimozal\" : YildirimOzal,\n",
    "    \"caiwenjuan\" : CaiWenjuan,\n",
    "    \"zhangjin\" : ZhangJin,\n",
    "    \"kongzhengmin\": KongZhengmin,\n",
    "    \"weixiaoyan\" : WeiXiaoyan,\n",
    "    \"gaojunli\": GaoJunLi,\n",
    "    \"khanzulfiqar\" : KhanZulfiqar,\n",
    "    \"zhengzhenyu\": ZhengZhenyu,\n",
    "    \"wangkejun\" : WangKejun,\n",
    "    \"chenchen\": ChenChen,\n",
    "    \"kimtaeyoung\" : KimTaeYoung,\n",
    "    \"genminxing\": GenMinxing,\n",
    "    \"fujiangmeng\" : FuJiangmeng,\n",
    "    \"shihaotian\" : ShiHaotian, \n",
    "    \"huangmeiling\": HuangMeiLing,\n",
    "    \"hongtan\": HongTan,\n",
    "    \"sharpar\" : SharPar,\n",
    "    \"daixili\": DaiXiLi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing a model: OhShuLih"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use TimeSeriesDatasetV2 custom Dataset to create an appropiate tensor for time series tasks.\n",
    "\n",
    "We will use TSFEDL_TopModule custom top_module proposed as a default nn.Module class to reshape the data into (batch_size, npred, out_features) to perform anomaly detection tasks on time series data.\n",
    "\n",
    "We will use tsfedl library implemented via S-ADL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 11:02:06.982794: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-05 11:02:06.982828: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-05 11:02:06.984022: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-05 11:02:06.991589: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-05 11:02:08.216575: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label_parser': True, 'algorithm_': 'OhShuLih', 'pytorch_params_': {}, 'in_features': 126, 'loss': CrossEntropyLoss(), 'metrics': None, 'optimizer': None, 'top_module': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/homeGPU/mbautista/s-adl-environment/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /mnt/homeGPU/mbautista/s-adl-environment/lib/python3 ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/mnt/homeGPU/mbautista/s-adl-environment/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /mnt/homeGPU/mbautista/s-adl-environment/lib/python3 ...\n",
      "/mnt/homeGPU/mbautista/s-adl-environment/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type             | Params\n",
      "--------------------------------------------------\n",
      "0 | loss         | MSELoss          | 0     \n",
      "1 | classifier   | TSFEDL_TopModule | 7.5 K \n",
      "2 | convolutions | Sequential       | 7.9 K \n",
      "3 | lstm         | LSTM             | 2.2 K \n",
      "--------------------------------------------------\n",
      "17.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.6 K    Total params\n",
      "0.071     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd579f286a243838603e6f0ed3dc6cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                           | 0/? [0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/homeGPU/mbautista/s-adl-environment/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 1, 126])) that is different to the input size (torch.Size([32, 126])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/mnt/homeGPU/mbautista/s-adl-environment/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([12, 1, 126])) that is different to the input size (torch.Size([12, 126])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<SADL.time_series.algorithms.tsfedl.TsfedlAnomalyDetection at 0x7ff5fe3ebd50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/homeGPU/mbautista/S-ADL\")\n",
    "from SADL.time_series.time_series_utils import TimeSeriesDatasetV2\n",
    "from SADL.time_series.time_series_utils import TSFEDL_TopModule\n",
    "import torch\n",
    "from SADL.time_series.algorithms import tsfedl\n",
    "\n",
    "train_dataset = TimeSeriesDatasetV2(torch.from_numpy(train_data).double(), window_size=4, forecast_size=1, permute_size = (1,0))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "kwargs = {\"algorithm_\": \"ohshulih\", \"loss\": torch.nn.MSELoss(),\"top_module\": TSFEDL_TopModule(in_features=20, out_features=126), \"max_epochs\": 1, \"in_features\":126, \"label_parser\": True}\n",
    "model1 = tsfedl.TsfedlAnomalyDetection(**kwargs)\n",
    "model1.model = model1.model.double()\n",
    "\n",
    "model1.fit(train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
