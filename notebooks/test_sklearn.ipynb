{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Models and Parameters (Get & Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'label_parser': None, 'algorithm_': 'SGDOneClassSVM', 'average': False, 'eta0': 0.0, 'fit_intercept': True, 'learning_rate': 'optimal', 'max_iter': 1000, 'nu': 0.15, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'tol': 1e-06, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# temporary solution for relative imports in case sadl is not installed\n",
    "# if sadl is installed, no need to use the line\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "from inspect import signature\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "from SADL.static_data.algorithms import sklearn\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "\n",
    "\n",
    "# Example settings\n",
    "n_samples = 300\n",
    "outliers_fraction = 0.15\n",
    "n_outliers = int(outliers_fraction * n_samples)\n",
    "n_inliers = n_samples - n_outliers\n",
    "\n",
    "model = EllipticEnvelope(contamination=outliers_fraction, random_state=42)\n",
    "\n",
    "#print(model.get_params())\n",
    "\n",
    "kwargs = {\"algorithm_\": \"elliptic\",\"contamination\":0.15, \"label_parser\": True}\n",
    "model1 = sklearn.SkLearnAnomalyDetection(**kwargs)\n",
    "#print(model1.get_params())\n",
    "\n",
    "kwargs = {\"algorithm_\": \"elliptic\",\"contamination\":0.4}\n",
    "model1 = sklearn.SkLearnAnomalyDetection(**kwargs)\n",
    "#print(model1.get_params())\n",
    "\n",
    "\n",
    "kwargs = {\"algorithm_\": \"sgdocsvm\", \"nu\" : 0.15, \"shuffle\":True, \"fit_intercept\":True, \"random_state\":42,\"tol\":1e-6}\n",
    "model2 = sklearn.SkLearnAnomalyDetection(**kwargs)\n",
    "print(model2.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 150\n",
      "Number of outliers: 50\n",
      "Ground truth shape is (200,). Outlier are 1 and inliers are 0.\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SkLearnAnomalyDetection' object has no attribute 'score_samples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#model.fit(X)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#model.score_samples(X)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#Fit models\u001b[39;00m\n\u001b[1;32m     28\u001b[0m model1\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_samples\u001b[49m(X)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SkLearnAnomalyDetection' object has no attribute 'score_samples'"
     ]
    }
   ],
   "source": [
    "# Define the number of inliers and outliers\n",
    "n_samples = 200\n",
    "outliers_fraction = 0.25\n",
    "\n",
    "# Compare given detectors under given settings\n",
    "# Initialize the data\n",
    "xx, yy = np.meshgrid(np.linspace(-7, 7, 100), np.linspace(-7, 7, 100))\n",
    "n_inliers = int((1. - outliers_fraction) * n_samples)\n",
    "n_outliers = int(outliers_fraction * n_samples)\n",
    "ground_truth = np.zeros(n_samples, dtype=int)\n",
    "ground_truth[-n_outliers:] = 1\n",
    "\n",
    "# Show the statics of the data\n",
    "print('Number of inliers: %i' % n_inliers)\n",
    "print('Number of outliers: %i' % n_outliers)\n",
    "print('Ground truth shape is {shape}. Outlier are 1 and inliers are 0.\\n'.format(shape=ground_truth.shape))\n",
    "print(ground_truth)\n",
    "\n",
    "X1 = 0.3 * np.random.randn(n_inliers // 2, 2)\n",
    "X2 = 0.3 * np.random.randn(n_inliers // 2, 2)\n",
    "X = np.r_[X1, X2]\n",
    "# Add outliers\n",
    "X = np.r_[X, np.random.uniform(low=-6, high=6, size=(n_outliers, 2))]\n",
    "\n",
    "#model.fit(X)\n",
    "#model.score_samples(X)\n",
    "#Fit models\n",
    "model1.fit(X)\n",
    "model1.model.score_samples(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Function & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00910062,  0.00844819,  0.00792779,  0.01053171,  0.0081789 ,\n",
       "        0.00961207,  0.00535795,  0.00936529,  0.00685113,  0.00923498,\n",
       "        0.00875967,  0.00807777,  0.00917998,  0.01016415,  0.00870156,\n",
       "        0.00862809,  0.00875269,  0.01001466,  0.00957266,  0.01216242,\n",
       "        0.00677529,  0.00936614,  0.00792772,  0.00780005,  0.00834745,\n",
       "        0.01113742,  0.00779147,  0.0080967 ,  0.00847872,  0.00935997,\n",
       "        0.0090977 ,  0.00692173,  0.00801638,  0.01074882,  0.00925003,\n",
       "        0.00935875,  0.01088476,  0.009174  ,  0.00759843,  0.00871302,\n",
       "        0.00666384,  0.01100839,  0.01126712,  0.00619302,  0.00816511,\n",
       "        0.00965291,  0.00870533,  0.00880395,  0.0069613 ,  0.00869981,\n",
       "        0.00782067,  0.01127395,  0.0076995 ,  0.01060094,  0.00944729,\n",
       "        0.01042164,  0.00806997,  0.00521373,  0.01082998,  0.01043398,\n",
       "        0.00730858,  0.01082579,  0.00738305,  0.01077221,  0.00625984,\n",
       "        0.00756777,  0.00971612,  0.00806257,  0.01114065,  0.00856617,\n",
       "        0.01025814,  0.00736537,  0.00775536,  0.00950739,  0.00970133,\n",
       "        0.0071776 ,  0.01208274,  0.00570669,  0.00823845,  0.00806909,\n",
       "        0.00822433,  0.0055931 ,  0.00710125,  0.00890865,  0.00762858,\n",
       "        0.00974222,  0.01146583,  0.01190558,  0.00835594,  0.00968909,\n",
       "        0.01080384,  0.00954449,  0.00832695,  0.01069744,  0.01054647,\n",
       "        0.00850398,  0.01103289,  0.00897098,  0.0075972 ,  0.01049827,\n",
       "        0.00726625,  0.01084438,  0.01101007,  0.01023358,  0.01063131,\n",
       "        0.00670639,  0.01070006,  0.00673347,  0.00925819,  0.00917091,\n",
       "        0.01123086,  0.01097775,  0.00772479,  0.01023259,  0.01001021,\n",
       "        0.00566403,  0.00979583,  0.00778869,  0.00729464,  0.00832176,\n",
       "        0.00934111,  0.00428816,  0.00703209,  0.00921034,  0.00630363,\n",
       "        0.00858767,  0.01221742,  0.01213794,  0.00739605,  0.01015713,\n",
       "        0.00651167,  0.01004651,  0.01059939,  0.0074795 ,  0.01060405,\n",
       "        0.0088987 ,  0.01272702,  0.01280912,  0.01172646,  0.00982436,\n",
       "        0.01050653,  0.00884159,  0.0070962 ,  0.0052235 ,  0.01270793,\n",
       "        0.0119683 ,  0.00934494,  0.00826091,  0.00975424,  0.01150978,\n",
       "        0.00445491,  0.01300717,  0.02308413, -0.01044921,  0.00100612,\n",
       "        0.01075231,  0.03430532, -0.02395723,  0.03130605,  0.00402073,\n",
       "        0.03508218,  0.00779983,  0.01869369, -0.02111729,  0.02320306,\n",
       "        0.03603135,  0.02284037,  0.01116273,  0.00220397,  0.03753918,\n",
       "        0.02362075,  0.00043651, -0.00175107,  0.04253144,  0.01177152,\n",
       "       -0.0316424 ,  0.01374953,  0.03006   , -0.02897093, -0.02398378,\n",
       "        0.02481415,  0.00625173, -0.00836678,  0.01222296, -0.019395  ,\n",
       "       -0.01947389,  0.01212645,  0.04624446,  0.03616092,  0.01544944,\n",
       "        0.00817663,  0.01731577,  0.05072055,  0.03745327,  0.03171808,\n",
       "        0.03837242, -0.01307812, -0.00976233,  0.02275361,  0.01655902])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X).decision_function(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
